{"version":3,"sources":["../src/llm.ts"],"sourcesContent":["// SPDX-FileCopyrightText: 2025 LiveKit, Inc.\n//\n// SPDX-License-Identifier: Apache-2.0\nimport type { APIConnectOptions } from '@livekit/agents';\nimport { DEFAULT_API_CONNECT_OPTIONS, inference, llm } from '@livekit/agents';\nimport { AzureOpenAI, OpenAI } from 'openai';\nimport type {\n  CerebrasChatModels,\n  ChatModels,\n  DeepSeekChatModels,\n  GroqChatModels,\n  MetaChatModels,\n  OctoChatModels,\n  PerplexityChatModels,\n  TelnyxChatModels,\n  TogetherChatModels,\n  XAIChatModels,\n} from './models.js';\n\nexport interface LLMOptions {\n  model: string | ChatModels;\n  apiKey?: string;\n  baseURL?: string;\n  user?: string;\n  temperature?: number;\n  client?: OpenAI;\n  toolChoice?: llm.ToolChoice;\n  parallelToolCalls?: boolean;\n  metadata?: Record<string, string>;\n  maxCompletionTokens?: number;\n  serviceTier?: string;\n  store?: boolean;\n}\n\nconst defaultLLMOptions: LLMOptions = {\n  model: 'gpt-4.1',\n  apiKey: process.env.OPENAI_API_KEY,\n  parallelToolCalls: true,\n};\n\nconst defaultAzureLLMOptions: LLMOptions = {\n  model: 'gpt-4.1',\n  apiKey: process.env.AZURE_API_KEY,\n};\n\nexport class LLM extends llm.LLM {\n  #opts: LLMOptions;\n  #client: OpenAI;\n  #providerFmt: llm.ProviderFormat;\n\n  /**\n   * Create a new instance of OpenAI LLM.\n   *\n   * @remarks\n   * `apiKey` must be set to your OpenAI API key, either using the argument or by setting the\n   * `OPENAI_API_KEY` environment variable.\n   */\n  constructor(\n    opts: Partial<LLMOptions> = defaultLLMOptions,\n    providerFmt: llm.ProviderFormat = 'openai',\n  ) {\n    super();\n\n    this.#opts = { ...defaultLLMOptions, ...opts };\n    this.#providerFmt = providerFmt;\n    if (this.#opts.apiKey === undefined) {\n      throw new Error('OpenAI API key is required, whether as an argument or as $OPENAI_API_KEY');\n    }\n\n    this.#client =\n      this.#opts.client ||\n      new OpenAI({\n        baseURL: opts.baseURL,\n        apiKey: opts.apiKey,\n      });\n  }\n\n  label(): string {\n    return 'openai.LLM';\n  }\n\n  get model(): string {\n    return this.#opts.model;\n  }\n\n  /**\n   * Create a new instance of OpenAI LLM with Azure.\n   *\n   * @remarks\n   * This automatically infers the following arguments from their corresponding environment variables if they are not provided:\n   * - `apiKey` from `AZURE_OPENAI_API_KEY`\n   * - `organization` from `OPENAI_ORG_ID`\n   * - `project` from `OPENAI_PROJECT_ID`\n   * - `azureAdToken` from `AZURE_OPENAI_AD_TOKEN`\n   * - `apiVersion` from `OPENAI_API_VERSION`\n   * - `azureEndpoint` from `AZURE_OPENAI_ENDPOINT`\n   */\n  static withAzure(\n    opts: {\n      model: string | ChatModels;\n      azureEndpoint?: string;\n      azureDeployment?: string;\n      apiVersion?: string;\n      apiKey?: string;\n      azureAdToken?: string;\n      azureAdTokenProvider?: () => Promise<string>;\n      organization?: string;\n      project?: string;\n      baseURL?: string;\n      user?: string;\n      temperature?: number;\n    } = defaultAzureLLMOptions,\n  ): LLM {\n    opts = { ...defaultAzureLLMOptions, ...opts };\n    if (opts.apiKey === undefined) {\n      throw new Error('Azure API key is required, whether as an argument or as $AZURE_API_KEY');\n    }\n\n    return new LLM({\n      temperature: opts.temperature,\n      user: opts.user,\n      client: new AzureOpenAI(opts),\n    });\n  }\n\n  /**\n   * Create a new instance of Cerebras LLM.\n   *\n   * @remarks\n   * `apiKey` must be set to your Cerebras API key, either using the argument or by setting the\n   * `CEREBRAS_API_KEY` environment variable.\n   */\n  static withCerebras(\n    opts: Partial<{\n      model: string | CerebrasChatModels;\n      apiKey?: string;\n      baseURL?: string;\n      user?: string;\n      temperature?: number;\n      client: OpenAI;\n    }> = {},\n  ): LLM {\n    opts.apiKey = opts.apiKey || process.env.CEREBRAS_API_KEY;\n    if (opts.apiKey === undefined) {\n      throw new Error(\n        'Cerebras API key is required, whether as an argument or as $CEREBRAS_API_KEY',\n      );\n    }\n\n    return new LLM({\n      model: 'llama3.1-8b',\n      baseURL: 'https://api.cerebras.ai/v1',\n      ...opts,\n    });\n  }\n\n  /**\n   * Create a new instance of Fireworks LLM.\n   *\n   * @remarks\n   * `apiKey` must be set to your Fireworks API key, either using the argument or by setting the\n   * `FIREWORKS_API_KEY` environment variable.\n   */\n  static withFireworks(opts: Partial<LLMOptions> = {}): LLM {\n    opts.apiKey = opts.apiKey || process.env.FIREWORKS_API_KEY;\n    if (opts.apiKey === undefined) {\n      throw new Error(\n        'Fireworks API key is required, whether as an argument or as $FIREWORKS_API_KEY',\n      );\n    }\n\n    return new LLM({\n      model: 'accounts/fireworks/models/llama-v3p1-70b-instruct',\n      baseURL: 'https://api.fireworks.ai/inference/v1',\n      ...opts,\n    });\n  }\n\n  /**\n   * Create a new instance of xAI LLM.\n   *\n   * @remarks\n   * `apiKey` must be set to your xAI API key, either using the argument or by setting the\n   * `XAI_API_KEY` environment variable.\n   */\n  static withXAI(\n    opts: Partial<{\n      model: string | XAIChatModels;\n      apiKey?: string;\n      baseURL?: string;\n      user?: string;\n      temperature?: number;\n      client: OpenAI;\n    }> = {},\n  ): LLM {\n    opts.apiKey = opts.apiKey || process.env.XAI_API_KEY;\n    if (opts.apiKey === undefined) {\n      throw new Error('xAI API key is required, whether as an argument or as $XAI_API_KEY');\n    }\n\n    return new LLM({\n      model: 'grok-2-public',\n      baseURL: 'https://api.x.ai/v1',\n      ...opts,\n    });\n  }\n\n  /**\n   * Create a new instance of Groq LLM.\n   *\n   * @remarks\n   * `apiKey` must be set to your Groq API key, either using the argument or by setting the\n   * `GROQ_API_KEY` environment variable.\n   */\n  static withGroq(\n    opts: Partial<{\n      model: string | GroqChatModels;\n      apiKey?: string;\n      baseURL?: string;\n      user?: string;\n      temperature?: number;\n      client: OpenAI;\n    }> = {},\n  ): LLM {\n    opts.apiKey = opts.apiKey || process.env.GROQ_API_KEY;\n    if (opts.apiKey === undefined) {\n      throw new Error('Groq API key is required, whether as an argument or as $GROQ_API_KEY');\n    }\n\n    return new LLM({\n      model: 'llama3-8b-8192',\n      baseURL: 'https://api.groq.com/openai/v1',\n      ...opts,\n    });\n  }\n\n  /**\n   * Create a new instance of DeepSeek LLM.\n   *\n   * @remarks\n   * `apiKey` must be set to your DeepSeek API key, either using the argument or by setting the\n   * `DEEPSEEK_API_KEY` environment variable.\n   */\n  static withDeepSeek(\n    opts: Partial<{\n      model: string | DeepSeekChatModels;\n      apiKey?: string;\n      baseURL?: string;\n      user?: string;\n      temperature?: number;\n      client: OpenAI;\n    }> = {},\n  ): LLM {\n    opts.apiKey = opts.apiKey || process.env.DEEPSEEK_API_KEY;\n    if (opts.apiKey === undefined) {\n      throw new Error(\n        'DeepSeek API key is required, whether as an argument or as $DEEPSEEK_API_KEY',\n      );\n    }\n\n    return new LLM({\n      model: 'deepseek-chat',\n      baseURL: 'https://api.deepseek.com/v1',\n      ...opts,\n    });\n  }\n\n  /**\n   * Create a new instance of OctoAI LLM.\n   *\n   * @remarks\n   * `apiKey` must be set to your OctoAI API key, either using the argument or by setting the\n   * `OCTOAI_TOKEN` environment variable.\n   */\n  static withOcto(\n    opts: Partial<{\n      model: string | OctoChatModels;\n      apiKey?: string;\n      baseURL?: string;\n      user?: string;\n      temperature?: number;\n      client: OpenAI;\n    }> = {},\n  ): LLM {\n    opts.apiKey = opts.apiKey || process.env.OCTOAI_TOKEN;\n    if (opts.apiKey === undefined) {\n      throw new Error('OctoAI API key is required, whether as an argument or as $OCTOAI_TOKEN');\n    }\n\n    return new LLM({\n      model: 'llama-2-13b-chat',\n      baseURL: 'https://text.octoai.run/v1',\n      ...opts,\n    });\n  }\n\n  /** Create a new instance of Ollama LLM. */\n  static withOllama(\n    opts: Partial<{\n      model: string;\n      baseURL?: string;\n      temperature?: number;\n      client: OpenAI;\n    }> = {},\n  ): LLM {\n    return new LLM({\n      model: 'llama-2-13b-chat',\n      baseURL: 'https://text.octoai.run/v1',\n      apiKey: 'ollama',\n      ...opts,\n    });\n  }\n\n  /**\n   * Create a new instance of PerplexityAI LLM.\n   *\n   * @remarks\n   * `apiKey` must be set to your PerplexityAI API key, either using the argument or by setting the\n   * `PERPLEXITY_API_KEY` environment variable.\n   */\n  static withPerplexity(\n    opts: Partial<{\n      model: string | PerplexityChatModels;\n      apiKey?: string;\n      baseURL?: string;\n      user?: string;\n      temperature?: number;\n      client: OpenAI;\n    }> = {},\n  ): LLM {\n    opts.apiKey = opts.apiKey || process.env.PERPLEXITY_API_KEY;\n    if (opts.apiKey === undefined) {\n      throw new Error(\n        'PerplexityAI API key is required, whether as an argument or as $PERPLEXITY_API_KEY',\n      );\n    }\n\n    return new LLM({\n      model: 'llama-3.1-sonar-small-128k-chat',\n      baseURL: 'https://api.perplexity.ai',\n      ...opts,\n    });\n  }\n\n  /**\n   * Create a new instance of TogetherAI LLM.\n   *\n   * @remarks\n   * `apiKey` must be set to your TogetherAI API key, either using the argument or by setting the\n   * `TOGETHER_API_KEY` environment variable.\n   */\n  static withTogether(\n    opts: Partial<{\n      model: string | TogetherChatModels;\n      apiKey?: string;\n      baseURL?: string;\n      user?: string;\n      temperature?: number;\n      client: OpenAI;\n    }> = {},\n  ): LLM {\n    opts.apiKey = opts.apiKey || process.env.TOGETHER_API_KEY;\n    if (opts.apiKey === undefined) {\n      throw new Error(\n        'TogetherAI API key is required, whether as an argument or as $TOGETHER_API_KEY',\n      );\n    }\n\n    return new LLM({\n      model: 'meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo',\n      baseURL: 'https://api.together.xyz/v1',\n      ...opts,\n    });\n  }\n\n  /**\n   * Create a new instance of Telnyx LLM.\n   *\n   * @remarks\n   * `apiKey` must be set to your Telnyx API key, either using the argument or by setting the\n   * `TELNYX_API_KEY` environment variable.\n   */\n  static withTelnyx(\n    opts: Partial<{\n      model: string | TelnyxChatModels;\n      apiKey?: string;\n      baseURL?: string;\n      user?: string;\n      temperature?: number;\n      client: OpenAI;\n    }> = {},\n  ): LLM {\n    opts.apiKey = opts.apiKey || process.env.TELNYX_API_KEY;\n    if (opts.apiKey === undefined) {\n      throw new Error('Telnyx API key is required, whether as an argument or as $TELNYX_API_KEY');\n    }\n\n    return new LLM({\n      model: 'meta-llama/Meta-Llama-3.1-70B-Instruct',\n      baseURL: 'https://api.telnyx.com/v2/ai',\n      ...opts,\n    });\n  }\n\n  /**\n   * Create a new instance of Meta Llama LLM.\n   *\n   * @remarks\n   * `apiKey` must be set to your Meta Llama API key, either using the argument or by setting the\n   * `LLAMA_API_KEY` environment variable.\n   */\n  static withMeta(\n    opts: Partial<{\n      apiKey?: string;\n      baseURL?: string;\n      client?: OpenAI;\n      model?: string | MetaChatModels;\n      temperature?: number;\n      user?: string;\n    }> = {},\n  ): LLM {\n    opts.apiKey = opts.apiKey || process.env.LLAMA_API_KEY;\n    opts.baseURL = opts.baseURL || 'https://api.llama.com/compat/v1/';\n    opts.model = opts.model || 'Llama-4-Maverick-17B-128E-Instruct-FP8';\n\n    if (opts.apiKey === undefined) {\n      throw new Error(\n        'Meta Llama API key is required, either as argument or set LLAMA_API_KEY environment variable',\n      );\n    }\n\n    return new LLM(opts);\n  }\n\n  chat({\n    chatCtx,\n    toolCtx,\n    connOptions = DEFAULT_API_CONNECT_OPTIONS,\n    parallelToolCalls,\n    toolChoice,\n    extraKwargs,\n  }: {\n    chatCtx: llm.ChatContext;\n    toolCtx?: llm.ToolContext;\n    connOptions?: APIConnectOptions;\n    parallelToolCalls?: boolean;\n    toolChoice?: llm.ToolChoice;\n    extraKwargs?: Record<string, any>;\n  }): LLMStream {\n    const extras: Record<string, any> = { ...extraKwargs }; // eslint-disable-line @typescript-eslint/no-explicit-any\n\n    if (this.#opts.metadata) {\n      extras.metadata = this.#opts.metadata;\n    }\n\n    if (this.#opts.user) {\n      extras.user = this.#opts.user;\n    }\n\n    if (this.#opts.maxCompletionTokens) {\n      extras.max_completion_tokens = this.#opts.maxCompletionTokens;\n    }\n\n    if (this.#opts.temperature) {\n      extras.temperature = this.#opts.temperature;\n    }\n\n    if (this.#opts.serviceTier) {\n      extras.service_tier = this.#opts.serviceTier;\n    }\n\n    if (this.#opts.store !== undefined) {\n      extras.store = this.#opts.store;\n    }\n\n    parallelToolCalls =\n      parallelToolCalls !== undefined ? parallelToolCalls : this.#opts.parallelToolCalls;\n    if (toolCtx && Object.keys(toolCtx).length > 0 && parallelToolCalls !== undefined) {\n      extras.parallel_tool_calls = parallelToolCalls;\n    }\n\n    toolChoice = toolChoice !== undefined ? toolChoice : this.#opts.toolChoice;\n    if (toolChoice) {\n      extras.tool_choice = toolChoice;\n    }\n\n    return new LLMStream(this as unknown as inference.LLM, {\n      model: this.#opts.model,\n      providerFmt: this.#providerFmt,\n      client: this.#client,\n      chatCtx,\n      toolCtx,\n      connOptions,\n      modelOptions: extras,\n      gatewayOptions: undefined, // OpenAI plugin doesn't use gateway authentication\n    });\n  }\n}\n\nexport class LLMStream extends inference.LLMStream {}\n"],"mappings":"AAIA,SAAS,6BAA6B,WAAW,WAAW;AAC5D,SAAS,aAAa,cAAc;AA6BpC,MAAM,oBAAgC;AAAA,EACpC,OAAO;AAAA,EACP,QAAQ,QAAQ,IAAI;AAAA,EACpB,mBAAmB;AACrB;AAEA,MAAM,yBAAqC;AAAA,EACzC,OAAO;AAAA,EACP,QAAQ,QAAQ,IAAI;AACtB;AAEO,MAAM,YAAY,IAAI,IAAI;AAAA,EAC/B;AAAA,EACA;AAAA,EACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,YACE,OAA4B,mBAC5B,cAAkC,UAClC;AACA,UAAM;AAEN,SAAK,QAAQ,EAAE,GAAG,mBAAmB,GAAG,KAAK;AAC7C,SAAK,eAAe;AACpB,QAAI,KAAK,MAAM,WAAW,QAAW;AACnC,YAAM,IAAI,MAAM,0EAA0E;AAAA,IAC5F;AAEA,SAAK,UACH,KAAK,MAAM,UACX,IAAI,OAAO;AAAA,MACT,SAAS,KAAK;AAAA,MACd,QAAQ,KAAK;AAAA,IACf,CAAC;AAAA,EACL;AAAA,EAEA,QAAgB;AACd,WAAO;AAAA,EACT;AAAA,EAEA,IAAI,QAAgB;AAClB,WAAO,KAAK,MAAM;AAAA,EACpB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAcA,OAAO,UACL,OAaI,wBACC;AACL,WAAO,EAAE,GAAG,wBAAwB,GAAG,KAAK;AAC5C,QAAI,KAAK,WAAW,QAAW;AAC7B,YAAM,IAAI,MAAM,wEAAwE;AAAA,IAC1F;AAEA,WAAO,IAAI,IAAI;AAAA,MACb,aAAa,KAAK;AAAA,MAClB,MAAM,KAAK;AAAA,MACX,QAAQ,IAAI,YAAY,IAAI;AAAA,IAC9B,CAAC;AAAA,EACH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,OAAO,aACL,OAOK,CAAC,GACD;AACL,SAAK,SAAS,KAAK,UAAU,QAAQ,IAAI;AACzC,QAAI,KAAK,WAAW,QAAW;AAC7B,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,WAAO,IAAI,IAAI;AAAA,MACb,OAAO;AAAA,MACP,SAAS;AAAA,MACT,GAAG;AAAA,IACL,CAAC;AAAA,EACH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,OAAO,cAAc,OAA4B,CAAC,GAAQ;AACxD,SAAK,SAAS,KAAK,UAAU,QAAQ,IAAI;AACzC,QAAI,KAAK,WAAW,QAAW;AAC7B,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,WAAO,IAAI,IAAI;AAAA,MACb,OAAO;AAAA,MACP,SAAS;AAAA,MACT,GAAG;AAAA,IACL,CAAC;AAAA,EACH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,OAAO,QACL,OAOK,CAAC,GACD;AACL,SAAK,SAAS,KAAK,UAAU,QAAQ,IAAI;AACzC,QAAI,KAAK,WAAW,QAAW;AAC7B,YAAM,IAAI,MAAM,oEAAoE;AAAA,IACtF;AAEA,WAAO,IAAI,IAAI;AAAA,MACb,OAAO;AAAA,MACP,SAAS;AAAA,MACT,GAAG;AAAA,IACL,CAAC;AAAA,EACH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,OAAO,SACL,OAOK,CAAC,GACD;AACL,SAAK,SAAS,KAAK,UAAU,QAAQ,IAAI;AACzC,QAAI,KAAK,WAAW,QAAW;AAC7B,YAAM,IAAI,MAAM,sEAAsE;AAAA,IACxF;AAEA,WAAO,IAAI,IAAI;AAAA,MACb,OAAO;AAAA,MACP,SAAS;AAAA,MACT,GAAG;AAAA,IACL,CAAC;AAAA,EACH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,OAAO,aACL,OAOK,CAAC,GACD;AACL,SAAK,SAAS,KAAK,UAAU,QAAQ,IAAI;AACzC,QAAI,KAAK,WAAW,QAAW;AAC7B,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,WAAO,IAAI,IAAI;AAAA,MACb,OAAO;AAAA,MACP,SAAS;AAAA,MACT,GAAG;AAAA,IACL,CAAC;AAAA,EACH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,OAAO,SACL,OAOK,CAAC,GACD;AACL,SAAK,SAAS,KAAK,UAAU,QAAQ,IAAI;AACzC,QAAI,KAAK,WAAW,QAAW;AAC7B,YAAM,IAAI,MAAM,wEAAwE;AAAA,IAC1F;AAEA,WAAO,IAAI,IAAI;AAAA,MACb,OAAO;AAAA,MACP,SAAS;AAAA,MACT,GAAG;AAAA,IACL,CAAC;AAAA,EACH;AAAA;AAAA,EAGA,OAAO,WACL,OAKK,CAAC,GACD;AACL,WAAO,IAAI,IAAI;AAAA,MACb,OAAO;AAAA,MACP,SAAS;AAAA,MACT,QAAQ;AAAA,MACR,GAAG;AAAA,IACL,CAAC;AAAA,EACH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,OAAO,eACL,OAOK,CAAC,GACD;AACL,SAAK,SAAS,KAAK,UAAU,QAAQ,IAAI;AACzC,QAAI,KAAK,WAAW,QAAW;AAC7B,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,WAAO,IAAI,IAAI;AAAA,MACb,OAAO;AAAA,MACP,SAAS;AAAA,MACT,GAAG;AAAA,IACL,CAAC;AAAA,EACH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,OAAO,aACL,OAOK,CAAC,GACD;AACL,SAAK,SAAS,KAAK,UAAU,QAAQ,IAAI;AACzC,QAAI,KAAK,WAAW,QAAW;AAC7B,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,WAAO,IAAI,IAAI;AAAA,MACb,OAAO;AAAA,MACP,SAAS;AAAA,MACT,GAAG;AAAA,IACL,CAAC;AAAA,EACH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,OAAO,WACL,OAOK,CAAC,GACD;AACL,SAAK,SAAS,KAAK,UAAU,QAAQ,IAAI;AACzC,QAAI,KAAK,WAAW,QAAW;AAC7B,YAAM,IAAI,MAAM,0EAA0E;AAAA,IAC5F;AAEA,WAAO,IAAI,IAAI;AAAA,MACb,OAAO;AAAA,MACP,SAAS;AAAA,MACT,GAAG;AAAA,IACL,CAAC;AAAA,EACH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,OAAO,SACL,OAOK,CAAC,GACD;AACL,SAAK,SAAS,KAAK,UAAU,QAAQ,IAAI;AACzC,SAAK,UAAU,KAAK,WAAW;AAC/B,SAAK,QAAQ,KAAK,SAAS;AAE3B,QAAI,KAAK,WAAW,QAAW;AAC7B,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,WAAO,IAAI,IAAI,IAAI;AAAA,EACrB;AAAA,EAEA,KAAK;AAAA,IACH;AAAA,IACA;AAAA,IACA,cAAc;AAAA,IACd;AAAA,IACA;AAAA,IACA;AAAA,EACF,GAOc;AACZ,UAAM,SAA8B,EAAE,GAAG,YAAY;AAErD,QAAI,KAAK,MAAM,UAAU;AACvB,aAAO,WAAW,KAAK,MAAM;AAAA,IAC/B;AAEA,QAAI,KAAK,MAAM,MAAM;AACnB,aAAO,OAAO,KAAK,MAAM;AAAA,IAC3B;AAEA,QAAI,KAAK,MAAM,qBAAqB;AAClC,aAAO,wBAAwB,KAAK,MAAM;AAAA,IAC5C;AAEA,QAAI,KAAK,MAAM,aAAa;AAC1B,aAAO,cAAc,KAAK,MAAM;AAAA,IAClC;AAEA,QAAI,KAAK,MAAM,aAAa;AAC1B,aAAO,eAAe,KAAK,MAAM;AAAA,IACnC;AAEA,QAAI,KAAK,MAAM,UAAU,QAAW;AAClC,aAAO,QAAQ,KAAK,MAAM;AAAA,IAC5B;AAEA,wBACE,sBAAsB,SAAY,oBAAoB,KAAK,MAAM;AACnE,QAAI,WAAW,OAAO,KAAK,OAAO,EAAE,SAAS,KAAK,sBAAsB,QAAW;AACjF,aAAO,sBAAsB;AAAA,IAC/B;AAEA,iBAAa,eAAe,SAAY,aAAa,KAAK,MAAM;AAChE,QAAI,YAAY;AACd,aAAO,cAAc;AAAA,IACvB;AAEA,WAAO,IAAI,UAAU,MAAkC;AAAA,MACrD,OAAO,KAAK,MAAM;AAAA,MAClB,aAAa,KAAK;AAAA,MAClB,QAAQ,KAAK;AAAA,MACb;AAAA,MACA;AAAA,MACA;AAAA,MACA,cAAc;AAAA,MACd,gBAAgB;AAAA;AAAA,IAClB,CAAC;AAAA,EACH;AACF;AAEO,MAAM,kBAAkB,UAAU,UAAU;AAAC;","names":[]}