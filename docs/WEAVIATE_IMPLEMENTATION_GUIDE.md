# Weaviate Implementation Guide

## Overview

This project uses **Weaviate** as a vector database to store and retrieve interview data, enabling semantic search and RAG (Retrieval-Augmented Generation) capabilities for AI-powered interview analysis. Weaviate stores interview transcripts, research goals, question plans, and psychological profiles with vector embeddings for intelligent retrieval.

## Architecture

### Core Components

1. **Weaviate Vector Database** - Stores all interview data with vector embeddings
2. **API Routes** - Handle CRUD operations and vector search
3. **Agent Integration** - AI agents store and retrieve data from Weaviate
4. **Session Management** - Comprehensive session lifecycle management

### Data Flow

```
Research Goal → Clarification Agent → Planner Agent → Interview Session
     ↓                ↓                    ↓              ↓
Weaviate ← ResearchGoal ← QuestionPlan ← InterviewSession ← InterviewChunk
     ↓
Vector Search → RAG → Follow-up Questions
```

## Weaviate Collections (Classes)

### 1. ResearchGoal
Stores research objectives and clarifications from the clarification agent.

**Schema:**
```json
{
  "class": "ResearchGoal",
  "properties": [
    { "name": "goalText", "dataType": ["text"] },
    { "name": "targetAudience", "dataType": ["text"] },
    { "name": "duration", "dataType": ["int"] },
    { "name": "sensitivity", "dataType": ["text"] },
    { "name": "createdAt", "dataType": ["date"] }
  ]
}
```

### 2. QuestionPlan
Stores interview scripts and question plans generated by the planner agent.

**Schema:**
```json
{
  "class": "QuestionPlan",
  "properties": [
    { "name": "researchGoalId", "dataType": ["text"] },
    { "name": "introduction", "dataType": ["text"] },
    { "name": "questions", "dataType": ["text[]"] },
    { "name": "followUps", "dataType": ["text"] },
    { "name": "createdAt", "dataType": ["date"] }
  ]
}
```

### 3. InterviewChunk
Stores individual interview transcript chunks with summaries and keywords.

**Schema:**
```json
{
  "class": "InterviewChunk",
  "properties": [
    { "name": "sessionId", "dataType": ["text"] },
    { "name": "speaker", "dataType": ["text"] },
    { "name": "text", "dataType": ["text"] },
    { "name": "summary", "dataType": ["text"] },
    { "name": "keywords", "dataType": ["text[]"] },
    { "name": "sentiment", "dataType": ["text"] },
    { "name": "timestamp", "dataType": ["date"] }
  ]
}
```

### 4. PsychProfile
Stores psychological profiles generated by the psychometric agent.

**Schema:**
```json
{
  "class": "PsychProfile",
  "properties": [
    { "name": "sessionId", "dataType": ["text"] },
    { "name": "openness", "dataType": ["number"] },
    { "name": "conscientiousness", "dataType": ["number"] },
    { "name": "extraversion", "dataType": ["number"] },
    { "name": "agreeableness", "dataType": ["number"] },
    { "name": "neuroticism", "dataType": ["number"] },
    { "name": "enneagramType", "dataType": ["int"] },
    { "name": "explanation", "dataType": ["text"] },
    { "name": "createdAt", "dataType": ["date"] }
  ]
}
```

### 5. InterviewSession
Stores complete interview session data with all settings and results.

**Schema:**
```json
{
  "class": "InterviewSession",
  "properties": [
    { "name": "sessionId", "dataType": ["text"] },
    { "name": "sessionUrl", "dataType": ["text"] },
    { "name": "researchGoal", "dataType": ["text"] },
    { "name": "targetAudience", "dataType": ["text"] },
    { "name": "duration", "dataType": ["int"] },
    { "name": "sensitivity", "dataType": ["text"] },
    { "name": "participantEmail", "dataType": ["text"] },
    { "name": "participantName", "dataType": ["text"] },
    { "name": "roomName", "dataType": ["text"] },
    { "name": "livekitToken", "dataType": ["text"] },
    { "name": "beyondPresenceAgentId", "dataType": ["text"] },
    { "name": "beyondPresenceSessionId", "dataType": ["text"] },
    { "name": "status", "dataType": ["text"] },
    { "name": "startTime", "dataType": ["date"] },
    { "name": "endTime", "dataType": ["date"] },
    { "name": "durationMinutes", "dataType": ["number"] },
    { "name": "script", "dataType": ["text"] },
    { "name": "transcript", "dataType": ["text"] },
    { "name": "insights", "dataType": ["text"] },
    { "name": "psychometricProfile", "dataType": ["text"] },
    { "name": "keyFindings", "dataType": ["text[]"] },
    { "name": "summary", "dataType": ["text"] },
    { "name": "createdAt", "dataType": ["date"] },
    { "name": "updatedAt", "dataType": ["date"] },
    { "name": "createdBy", "dataType": ["text"] },
    { "name": "tags", "dataType": ["text[]"] },
    { "name": "isPublic", "dataType": ["boolean"] },
    { "name": "accessCode", "dataType": ["text"] }
  ]
}
```

## API Endpoints

### Core Weaviate Operations
- **POST** `/api/weaviate` - Main Weaviate operations endpoint
  - `test_connection` - Test Weaviate connectivity
  - `create_schema` - Initialize database schema
  - `store` - Store data in collections
  - `search` - Vector search with semantic similarity

### Session Management
- **POST** `/api/weaviate/sessions` - Session CRUD operations
  - `create_schema` - Initialize session schema
  - `create_session` - Create new interview session
  - `get_session` - Retrieve session by ID
  - `update_session` - Update session data
  - `list_sessions` - List sessions with filters
  - `delete_session` - Delete session

### Connection Testing
- **GET** `/api/weaviate/test-connection` - Test Weaviate connection
- **POST** `/api/weaviate/init` - Initialize Weaviate schema

## Agent Integration

### 1. Clarification Agent (`/api/agents/clarification`)
- **Purpose**: Clarifies research goals and stores them in Weaviate
- **Weaviate Integration**: Stores research goals in `ResearchGoal` collection
- **Data Stored**: Goal text, clarifications, brief, creation timestamp

### 2. Planner Agent (`/api/agents/planner`)
- **Purpose**: Generates interview scripts and question plans
- **Weaviate Integration**: Stores question plans in `QuestionPlan` collection
- **Data Stored**: Research goal ID, introduction, questions array, follow-ups

### 3. Interviewer Agent (`/api/agents/interviewer`)
- **Purpose**: Conducts interviews using RAG for better follow-up questions
- **Weaviate Integration**: Searches `InterviewChunk` collection for similar responses
- **RAG Usage**: Retrieves similar past responses to generate contextual follow-ups

### 4. Summarizer Agent (`/api/agents/summarizer`)
- **Purpose**: Summarizes interview chunks and extracts insights
- **Weaviate Integration**: Stores chunks in `InterviewChunk` collection
- **Data Stored**: Session ID, speaker, text, summary, keywords, sentiment

### 5. Psychometric Agent (`/api/agents/psychometric`)
- **Purpose**: Analyzes personality traits and generates psychological profiles
- **Weaviate Integration**: Stores profiles in `PsychProfile` collection
- **Data Stored**: Big Five traits, Enneagram type, explanations

## Configuration

### Environment Variables

```bash
# Weaviate Configuration
WEAVIATE_HOST=localhost:8081  # or your-cloud-url.weaviate.network
WEAVIATE_API_KEY=your_api_key_here

# OpenAI Configuration (required for vectorization)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_APIKEY=your_openai_api_key_here  # Weaviate requires this spelling

# Application Configuration
NEXT_PUBLIC_BASE_URL=http://localhost:3000
```

### Docker Configuration

The project includes Docker Compose configuration for local Weaviate deployment:

```yaml
services:
  weaviate:
    image: semitechnologies/weaviate:1.25.3
    container_name: ai-interview-weaviate
    ports:
      - "8081:8080"
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'none'
      ENABLE_MODULES: 'text2vec-openai,text2vec-cohere,text2vec-huggingface,ref2vec-centroid,generative-openai,qna-openai'
      CLUSTER_HOSTNAME: 'node1'
    volumes:
      - weaviate_data:/var/lib/weaviate
```

### Dependencies

```json
{
  "dependencies": {
    "weaviate-ts-client": "^1.5.0"
  }
}
```

## Setup Instructions

### 1. Local Development Setup

```bash
# Start Weaviate with Docker Compose
cd interview
docker-compose up weaviate

# Install dependencies
npm install

# Configure environment variables
cp env.example .env.local
# Edit .env.local with your API keys

# Test connection
curl http://localhost:3000/api/weaviate/test-connection

# Initialize schema
curl -X POST http://localhost:3000/api/weaviate/init
```

### 2. Cloud Setup

For Weaviate Cloud deployment:

1. **Get Cloud Credentials**:
   - Go to [console.weaviate.cloud](https://console.weaviate.cloud)
   - Create or select a cluster
   - Copy cluster URL and API key

2. **Update Environment**:
   ```bash
   WEAVIATE_HOST=your-cluster-url.weaviate.network
   WEAVIATE_API_KEY=your-api-key-here
   ```

3. **Test Connection**:
   ```bash
   curl http://localhost:3000/api/weaviate/test-connection
   ```

## Usage Examples

### 1. Store Research Goal

```javascript
const response = await fetch('/api/weaviate', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    action: 'store',
    className: 'ResearchGoal',
    data: {
      goalText: 'Understand user flirting habits',
      targetAudience: 'Young adults 18-30',
      duration: 30,
      sensitivity: 'medium',
      createdAt: new Date().toISOString()
    }
  })
});
```

### 2. Search Similar Responses

```javascript
const response = await fetch('/api/weaviate', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    action: 'search',
    className: 'InterviewChunk',
    data: {
      query: 'dating preferences',
      limit: 5,
      nearText: 'dating preferences'
    }
  })
});
```

### 3. Create Interview Session

```javascript
const sessionManager = new SessionManager();
const session = await sessionManager.createSession({
  researchGoal: 'Understand user flirting habits',
  targetAudience: 'Young adults 18-30',
  duration: 30,
  participantEmail: 'user@example.com'
});
```

## Vector Search Implementation

### Semantic Search
Weaviate uses vector embeddings to enable semantic search across interview data:

```javascript
// Search for similar interview chunks
const searchResults = await client.graphql
  .get()
  .withClassName('InterviewChunk')
  .withFields('text summary keywords sentiment')
  .withNearText({
    concepts: ['user dating preferences'],
    certainty: 0.7
  })
  .withLimit(5)
  .do();
```

### RAG Integration
The interviewer agent uses RAG to improve follow-up questions:

```javascript
// In interviewer agent
const similarResponses = await searchWeaviate('InterviewChunk', participantResponse, 3);
const similarContext = similarResponses.results?.map(r => r.text).join('\n') || '';

// Use context in AI prompt
const userPrompt = `
Participant Response: ${participantResponse}
Similar responses from past interviews: ${similarContext}
Based on similar past responses, generate appropriate follow-up questions.
`;
```

## Session Management

The `SessionManager` class provides comprehensive session lifecycle management:

### Key Methods

```javascript
// Create session
const session = await sessionManager.createSession(sessionData);

// Get session
const session = await sessionManager.getSession(sessionId);

// Update session
const updatedSession = await sessionManager.updateSession(sessionId, updates);

// List sessions
const sessions = await sessionManager.listSessions({ status: 'completed' });

// Complete session
const completedSession = await sessionManager.completeSession(sessionId, summary, keyFindings);

// Add transcript entry
await sessionManager.addTranscriptEntry(sessionId, {
  speaker: 'participant',
  text: 'I prefer online dating apps',
  timestamp: new Date().toISOString()
});
```

## Troubleshooting

### Common Issues

1. **Connection Failed**
   - Check `WEAVIATE_HOST` and `WEAVIATE_API_KEY` environment variables
   - Verify Weaviate instance is running
   - Test with `/api/weaviate/test-connection`

2. **Schema Not Created**
   - Run schema initialization: `POST /api/weaviate/init`
   - Check Weaviate logs for errors
   - Verify API key has write permissions

3. **Vector Search Not Working**
   - Ensure OpenAI API key is configured
   - Check `text2vec-openai` module is enabled
   - Verify data is being stored with embeddings

4. **Data Not Persisting**
   - Check Docker volume mounting
   - Verify persistence configuration
   - Check Weaviate logs for storage errors

### Debug Commands

```bash
# Test Weaviate connection
curl http://localhost:3000/api/weaviate/test-connection

# Check schema
curl http://localhost:3000/api/weaviate -X POST -H "Content-Type: application/json" -d '{"action":"test_connection"}'

# Initialize schema
curl http://localhost:3000/api/weaviate/init -X POST

# Check Docker logs
docker logs ai-interview-weaviate
```

## Performance Considerations

### Optimization Strategies

1. **Batch Operations**: Group multiple operations to reduce API calls
2. **Caching**: Cache frequently accessed data
3. **Indexing**: Use appropriate vector index configurations
4. **Pagination**: Implement pagination for large result sets
5. **Connection Pooling**: Reuse Weaviate client connections

### Monitoring

- Monitor Weaviate metrics and performance
- Track API response times
- Monitor memory usage and disk space
- Set up alerts for connection failures

## Security Considerations

1. **API Key Management**: Store API keys securely in environment variables
2. **Access Control**: Implement proper authentication and authorization
3. **Data Encryption**: Use HTTPS for cloud connections
4. **Input Validation**: Validate all data before storing in Weaviate
5. **Rate Limiting**: Implement rate limiting for API endpoints

## Future Enhancements

1. **Multi-tenancy**: Support multiple research organizations
2. **Advanced Analytics**: Cross-session pattern analysis
3. **Real-time Updates**: WebSocket integration for live updates
4. **Export Features**: Data export in various formats
5. **Backup & Recovery**: Automated backup and recovery procedures

## Conclusion

Weaviate provides a robust foundation for storing and retrieving interview data with semantic search capabilities. The implementation supports the full interview lifecycle from research goal clarification to psychological profile generation, enabling AI-powered insights and improved interview experiences through RAG-enhanced questioning.

The modular architecture allows for easy extension and customization while maintaining data consistency and performance across all interview sessions.
